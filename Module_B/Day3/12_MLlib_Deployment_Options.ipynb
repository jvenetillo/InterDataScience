{"cells":[{"cell_type":"markdown","source":["![](https://files.training.databricks.com/images/301/deployment_options_mllib.png)\n\nThere are four main deployment options:\n* Batch pre-compute\n* Structured streaming\n* Low-latency model serving\n* Mobile/embedded (outside scope of class)\n\nWe have already seen how to do batch predictions using Spark. Now let's look at how to make predictions on streaming data.\n\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) In this lesson you:<br>\n - Apply a SparkML model on a simulated stream of data"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5663cb6d-4dc4-4223-b71d-b3c18c821af7","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%run \"./Includes/Classroom-Setup\""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"794b309c-ac3e-4ad1-8d4a-9eccc03aee00","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Load in Model & Data\n\nWe are loading in a repartitioned version of our dataset (100 partitions instead of 4) to see more incremental progress of the streaming predictions."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"bdbe05f8-c33b-44d5-9db0-a5672b90acad","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.ml.pipeline import PipelineModel\n\npipelinePath = \"dbfs:/mnt/training/airbnb/sf-listings/models/sf-listings-2019-03-06/pipeline_model\"\npipelineModel = PipelineModel.load(pipelinePath)\n\nrepartitionedPath =  \"dbfs:/mnt/training/airbnb/sf-listings/sf-listings-2019-03-06-clean-100p.parquet/\"\nschema = spark.read.parquet(repartitionedPath).schema"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b5fbede3-d269-43d0-9c9c-49b086daeccd","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Simulate streaming data\n\n**NOTE**: You must specify a schema when creating a streaming source DataFrame."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7dba846a-3bfb-48b5-ab5f-ed73fb2ec8a3","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["streamingData = (spark\n                 .readStream\n                 .schema(schema) # Can set the schema this way\n                 .option(\"maxFilesPerTrigger\", 1)\n                 .parquet(repartitionedPath))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a668499a-4d8d-44ea-96ad-e78c5025ced3","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Make Predictions"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f5840a4e-e44a-41b2-a232-6d8efa6f8d0b","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["streamPred = pipelineModel.transform(streamingData)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b5dac687-b618-45c6-9d84-c1feeadb4740","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Let's save our results."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ee782735-bfcc-4fcd-b2de-c2252c8508de","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import re\n\ncheckpointDir = userhome + \"/machine-learning/stream_1p_checkpoint\"\n# Clear out the checkpointing directory\ndbutils.fs.rm(checkpointDir, True) \n\n(streamPred\n .writeStream\n .format(\"memory\")\n .option(\"checkpointLocation\", checkpointDir)\n .outputMode(\"append\")\n .queryName(\"pred_stream_1p\")\n .start())"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3e5318c2-3f98-419e-9b44-4fce9d87216f","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["untilStreamIsReady(\"pred_stream_1p\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d9930de1-635e-4897-9ac7-3b2a0ed0750d","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["While this is running, take a look at the new Structured Streaming tab in the Spark UI."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d4f5b076-317c-4743-bd63-022f57384c94","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["display(\n  sql(\"select * from pred_stream_1p\")\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9406a277-30c5-4268-987b-300ad77b263d","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["display(\n  sql(\"select count(*) from pred_stream_1p\")\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"040f6d6b-4633-47d5-b8cb-31b3379860ee","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Now that we are done, make sure to stop the stream"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c5bacb40-efd0-4c28-915c-9d0384eacd71","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["for stream in spark.streams.active:\n  print(f\"Stopping {stream.name}\")\n  stream.stop() # Stop the stream"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"169aca1d-7f4d-4c53-a3aa-b8893838f63e","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### What about Model Export?\n\n* [MLeap](https://mleap-docs.combust.ml/)\n  * Company that developed MLeap is no longer supporting it, and MLeap does not yet support Scala 2.12/Spark 3.0\n* [ONNX](https://onnx.ai/)\n  * ONNX is very popular in the deep learning community allowing developers to switch between libraries and languages, but only has experimental support for MLlib.\n* DIY (Reimplement it yourself)\n  * Error-prone, fragile\n* 3rd party libraries\n  * See XGBoost notebook\n  * [H2O](https://www.h2o.ai/products/h2o-sparkling-water/)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c250310c-b6fc-42c5-ac0f-e5b809f5f49d","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["### Low-Latency Serving Solutions\n\nLow-latency serving can operate as quickly as tens to hundreds of milliseconds.  Custom solutions are normally backed by Docker and/or Flask (though Flask generally isn't recommended in production unless significant precations are taken).  Managed solutions also include:<br><br>\n\n* [MLflow Model Serving (Preview)](https://databricks.com/blog/2020/06/25/announcing-mlflow-model-serving-on-databricks.html)\n* [Azure Machine Learning](https://azure.microsoft.com/en-us/services/machine-learning/)\n* [SageMaker](https://aws.amazon.com/sagemaker/)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d207ac2e-8603-48fc-954e-cd8227bf272b","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["-sandbox\n&copy; 2020 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"29225705-7d89-4075-bd83-c8c669415b1c","inputWidgets":{},"title":""}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"12_MLlib_Deployment_Options","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":74902913649391}},"nbformat":4,"nbformat_minor":0}
