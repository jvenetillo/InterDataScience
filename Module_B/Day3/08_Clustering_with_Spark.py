# Databricks notebook source
# MAGIC %md
# MAGIC ## [Clustering with Spark](https://spark.apache.org/docs/latest/ml-clustering.html)  
# MAGIC 
# MAGIC This notebook describes clustering algorithms in Spark MLlib.  
# MAGIC The guide for clustering in the RDD-based API also has relevant information about these algorithms.
# MAGIC 
# MAGIC ### Table of Contents
# MAGIC 
# MAGIC + K-means
# MAGIC + Input Columns
# MAGIC + Output Columns
# MAGIC + Latent Dirichlet allocation (LDA)
# MAGIC + Bisecting k-means
# MAGIC + Gaussian Mixture Model (GMM)
# MAGIC + Input Columns
# MAGIC + Output Columns
# MAGIC + Power Iteration Clustering (PIC)

# COMMAND ----------

# MAGIC %md
# MAGIC #### [K-means](https://github.com/apache/spark/blob/master/examples/src/main/python/mllib/k_means_example.py)  
# MAGIC 
# MAGIC [k-means](http://en.wikipedia.org/wiki/K-means_clustering) is one of the most commonly used clustering algorithms that clusters the data points into a predefined number of clusters. The MLlib implementation includes a parallelized variant of the k-means++ method called kmeans||.
# MAGIC 
# MAGIC KMeans is implemented as an Estimator and generates a KMeansModel as the base model.
# MAGIC 
# MAGIC 
# MAGIC <h3 id="input-columns">Input Columns</h3>
# MAGIC 
# MAGIC <table class="table">
# MAGIC   <thead>
# MAGIC     <tr>
# MAGIC       <th align="left">Param name</th>
# MAGIC       <th align="left">Type(s)</th>
# MAGIC       <th align="left">Default</th>
# MAGIC       <th align="left">Description</th>
# MAGIC     </tr>
# MAGIC   </thead>
# MAGIC   <tbody>
# MAGIC     <tr>
# MAGIC       <td>featuresCol</td>
# MAGIC       <td>Vector</td>
# MAGIC       <td>"features"</td>
# MAGIC       <td>Feature vector</td>
# MAGIC     </tr>
# MAGIC   </tbody>
# MAGIC </table>
# MAGIC 
# MAGIC <h3 id="output-columns">Output Columns</h3>
# MAGIC 
# MAGIC <table class="table">
# MAGIC   <thead>
# MAGIC     <tr>
# MAGIC       <th align="left">Param name</th>
# MAGIC       <th align="left">Type(s)</th>
# MAGIC       <th align="left">Default</th>
# MAGIC       <th align="left">Description</th>
# MAGIC     </tr>
# MAGIC   </thead>
# MAGIC   <tbody>
# MAGIC     <tr>
# MAGIC       <td>predictionCol</td>
# MAGIC       <td>Int</td>
# MAGIC       <td>"prediction"</td>
# MAGIC       <td>Predicted cluster center</td>
# MAGIC     </tr>
# MAGIC   </tbody>
# MAGIC </table>

# COMMAND ----------

import os
os.getcwd()

# Notes on reading files for Spark within Databricks
# https://docs.databricks.com/_static/notebooks/files-in-repos.html

# COMMAND ----------

from pyspark.ml.clustering import KMeans
from pyspark.ml.evaluation import ClusteringEvaluator

# Loads data.
dataset = spark.read.format("libsvm").load(f"file:{os.getcwd()}/data/mllib/sample_kmeans_data.txt")

# Trains a k-means model.
kmeans = KMeans().setK(2).setSeed(1)
model = kmeans.fit(dataset)

# Make predictions
predictions = model.transform(dataset)

# Evaluate clustering by computing Silhouette score
evaluator = ClusteringEvaluator()

silhouette = evaluator.evaluate(predictions)
print("Silhouette with squared euclidean distance = " + str(silhouette))

# Shows the result.
centers = model.clusterCenters()
print("Cluster Centers: ")
for center in centers:
    print(center)

# COMMAND ----------

# MAGIC %md
# MAGIC #### [Latent Dirichlet allocation (LDA)](https://github.com/apache/spark/blob/master/examples/src/main/python/ml/lda_example.py)  
# MAGIC 
# MAGIC LDA is implemented as an Estimator that supports both EMLDAOptimizer and OnlineLDAOptimizer, and generates a LDAModel as the base model.
# MAGIC Expert users may cast a LDAModel generated by EMLDAOptimizer to a DistributedLDAModel if needed.

# COMMAND ----------

from pyspark.ml.clustering import LDA

# Loads data.
dataset = spark.read.format("libsvm").load(f"file:{os.getcwd()}/data/mllib/sample_lda_libsvm_data.txt")

# Trains a LDA model.
lda = LDA(k=10, maxIter=10)
model = lda.fit(dataset)

ll = model.logLikelihood(dataset)
lp = model.logPerplexity(dataset)
print("The lower bound on the log likelihood of the entire corpus: " + str(ll))
print("The upper bound on perplexity: " + str(lp))

# Describe topics.
topics = model.describeTopics(3)
print("The topics described by their top-weighted terms:")
topics.show(truncate=False)

# Shows the result
transformed = model.transform(dataset)
transformed.show(truncate=False)

# COMMAND ----------

# MAGIC %md
# MAGIC #### [Bisecting k-means](https://github.com/apache/spark/blob/master/examples/src/main/python/ml/bisecting_k_means_example.py)
# MAGIC 
# MAGIC Bisecting k-means is a kind of [hierarchical clustering](https://en.wikipedia.org/wiki/Hierarchical_clustering) using a divisive (or “top-down”) approach: all observations start in one cluster, and splits are performed recursively as one moves down the hierarchy.  
# MAGIC 
# MAGIC Bisecting K-means can often be much faster than regular K-means, but it will generally produce a different clustering.  
# MAGIC 
# MAGIC BisectingKMeans is implemented as an Estimator and generates a BisectingKMeansModel as the base model.  

# COMMAND ----------

from pyspark.ml.clustering import BisectingKMeans
from pyspark.ml.evaluation import ClusteringEvaluator

# Loads data.
dataset = spark.read.format("libsvm").load(f"file:{os.getcwd()}/data/mllib/sample_kmeans_data.txt")

# Trains a bisecting k-means model.
bkm = BisectingKMeans().setK(2).setSeed(1)
model = bkm.fit(dataset)

# Make predictions
predictions = model.transform(dataset)

# Evaluate clustering by computing Silhouette score
evaluator = ClusteringEvaluator()

silhouette = evaluator.evaluate(predictions)
print("Silhouette with squared euclidean distance = " + str(silhouette))

# Shows the result.
print("Cluster Centers: ")
centers = model.clusterCenters()
for center in centers:
    print(center)

# COMMAND ----------

# MAGIC %md
# MAGIC #### [Gaussian Mixture Model (GMM)](https://github.com/apache/spark/blob/master/examples/src/main/python/ml/gaussian_mixture_example.py)
# MAGIC 
# MAGIC A [Gaussian Mixture Model](http://en.wikipedia.org/wiki/Mixture_model#Multivariate_Gaussian_mixture_model) represents a composite distribution whereby points are drawn from one of k Gaussian sub-distributions, each with its own probability.  
# MAGIC The spark.ml implementation uses the [expectation-maximization](http://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm) algorithm to induce the maximum-likelihood model given a set of samples.  
# MAGIC 
# MAGIC GaussianMixture is implemented as an Estimator and generates a GaussianMixtureModel as the base model.  
# MAGIC 
# MAGIC <h3 id="input-columns-1">Input Columns</h3>
# MAGIC 
# MAGIC <table class="table">
# MAGIC   <thead>
# MAGIC     <tr>
# MAGIC       <th align="left">Param name</th>
# MAGIC       <th align="left">Type(s)</th>
# MAGIC       <th align="left">Default</th>
# MAGIC       <th align="left">Description</th>
# MAGIC     </tr>
# MAGIC   </thead>
# MAGIC   <tbody>
# MAGIC     <tr>
# MAGIC       <td>featuresCol</td>
# MAGIC       <td>Vector</td>
# MAGIC       <td>"features"</td>
# MAGIC       <td>Feature vector</td>
# MAGIC     </tr>
# MAGIC   </tbody>
# MAGIC </table>
# MAGIC 
# MAGIC <h3 id="output-columns-1">Output Columns</h3>
# MAGIC 
# MAGIC <table class="table">
# MAGIC   <thead>
# MAGIC     <tr>
# MAGIC       <th align="left">Param name</th>
# MAGIC       <th align="left">Type(s)</th>
# MAGIC       <th align="left">Default</th>
# MAGIC       <th align="left">Description</th>
# MAGIC     </tr>
# MAGIC   </thead>
# MAGIC   <tbody>
# MAGIC     <tr>
# MAGIC       <td>predictionCol</td>
# MAGIC       <td>Int</td>
# MAGIC       <td>"prediction"</td>
# MAGIC       <td>Predicted cluster center</td>
# MAGIC     </tr>
# MAGIC     <tr>
# MAGIC       <td>probabilityCol</td>
# MAGIC       <td>Vector</td>
# MAGIC       <td>"probability"</td>
# MAGIC       <td>Probability of each cluster</td>
# MAGIC     </tr>
# MAGIC   </tbody>
# MAGIC </table>

# COMMAND ----------

from pyspark.ml.clustering import GaussianMixture

# loads data
dataset = spark.read.format("libsvm").load(f"file:{os.getcwd()}/data/mllib/sample_kmeans_data.txt")

gmm = GaussianMixture().setK(2).setSeed(538009335)
model = gmm.fit(dataset)

print("Gaussians shown as a DataFrame: ")
model.gaussiansDF.show(truncate=False)

# COMMAND ----------

# MAGIC %md
# MAGIC #### [Power Iteration Clustering (PIC)](https://github.com/apache/spark/blob/master/examples/src/main/python/ml/power_iteration_clustering_example.py)
# MAGIC 
# MAGIC Power Iteration Clustering (PIC) is a scalable graph clustering algorithm developed by [Lin and Cohen](http://www.cs.cmu.edu/~frank/papers/icml2010-pic-final.pdf). From the abstract: PIC finds a very low-dimensional embedding of a dataset using truncated power iteration on a normalized pair-wise similarity matrix of the data.
# MAGIC 
# MAGIC spark.ml’s PowerIterationClustering implementation takes the following parameters:
# MAGIC 
# MAGIC + k: the number of clusters to create
# MAGIC + initMode: param for the initialization algorithm
# MAGIC + maxIter: param for maximum number of iterations
# MAGIC + srcCol: param for the name of the input column for source vertex IDs
# MAGIC + dstCol: name of the input column for destination vertex IDs
# MAGIC + weightCol: Param for weight column name

# COMMAND ----------

from pyspark.ml.clustering import PowerIterationClustering

df = spark.createDataFrame([
    (0, 1, 1.0),
    (0, 2, 1.0),
    (1, 2, 1.0),
    (3, 4, 1.0),
    (4, 0, 0.1)
], ["src", "dst", "weight"])

pic = PowerIterationClustering(k=2, maxIter=20, initMode="degree", weightCol="weight")

# Shows the cluster assignment
pic.assignClusters(df).show()

# COMMAND ----------

# MAGIC %md
# MAGIC 
# MAGIC Licensed to the Apache Software Foundation (ASF) under one or more
# MAGIC contributor license agreements.  See the NOTICE file distributed with
# MAGIC this work for additional information regarding copyright ownership.
# MAGIC The ASF licenses this file to You under the Apache License, Version 2.0
# MAGIC (the "License"); you may not use this file except in compliance with
# MAGIC the License.  You may obtain a copy of the License at
# MAGIC http://www.apache.org/licenses/LICENSE-2.0
# MAGIC 
# MAGIC Unless required by applicable law or agreed to in writing, software
# MAGIC distributed under the License is distributed on an "AS IS" BASIS,
# MAGIC WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# MAGIC See the License for the specific language governing permissions and
# MAGIC limitations under the License.
