{"cells":[{"cell_type":"markdown","source":["# Training with Pandas UDFs\n\nThis notebook demonstrates how to use Pandas UDFs to manage and scale machine learning models for IoT devices. \n\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) In this lesson you:<br>\n - Use `.groupBy().applyInPandas()` to build many models in parallel for each IoT Device"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d392ca6e-d0af-482f-a88d-240c8baf08a3","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["Create dummy data with:\n- `device_id`: 10 different devices\n- `record_id`: 10k unique records\n- `feature_1`: a feature for model training\n- `feature_2`: a feature for model training\n- `feature_3`: a feature for model training\n- `label`: the variable we're trying to predict"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f58927a1-e113-4014-b4b6-3637a5529551","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import pyspark.sql.functions as f\n\ndf = (spark.range(1000*100)\n  .select(f.col(\"id\").alias(\"record_id\"), (f.col(\"id\")%10).alias(\"device_id\"))\n  .withColumn(\"feature_1\", f.rand() * 1)\n  .withColumn(\"feature_2\", f.rand() * 2)\n  .withColumn(\"feature_3\", f.rand() * 3)\n  .withColumn(\"label\", (f.col(\"feature_1\") + f.col(\"feature_2\") + f.col(\"feature_3\")) + f.rand())\n)\n\ndisplay(df)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"14734d41-260e-4b63-a2e1-1ab20d9fd679","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Define the return schema"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"85393e27-0a85-47c4-8f35-0e4812b97c25","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import pyspark.sql.types as t\n\ntrainReturnSchema = t.StructType([\n  t.StructField(\"device_id\", t.IntegerType()), # unique device ID\n  t.StructField(\"n_used\", t.IntegerType()),    # number of records used in training\n  t.StructField(\"model_path\", t.StringType()), # path to the model for a given device\n  t.StructField(\"mse\", t.FloatType())          # metric for model performance\n])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7e472a32-606c-4345-99ed-6827e90ec39c","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Define a pandas UDF that takes all the data for a given device, train a model, saves it as a nested run, and returns a spark object with the above schema"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"029cb137-212d-4412-8fc5-3d7f216d42c5","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import mlflow\nimport mlflow.sklearn\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\ndef train_model(df_pandas: pd.DataFrame) -> pd.DataFrame:\n  \"\"\"\n  Trains an sklearn model on grouped instances\n  \"\"\"\n  # Pull metadata\n  device_id = df_pandas[\"device_id\"].iloc[0]\n  n_used = df_pandas.shape[0]\n  run_id = df_pandas[\"run_id\"].iloc[0] # Pulls run ID to do a nested run\n  \n  # Train the model\n  X = df_pandas[[\"feature_1\", \"feature_2\", \"feature_3\"]]\n  y = df_pandas[\"label\"]\n  rf = RandomForestRegressor()\n  rf.fit(X, y)\n\n  # Evaluate the model\n  predictions = rf.predict(X)\n  mse = mean_squared_error(y, predictions) # Note we could add a train/test split\n \n  # Resume the top-level training\n  with mlflow.start_run(run_id=run_id):\n    # Create a nested run for the specific device\n    with mlflow.start_run(run_name=str(device_id), nested=True) as run:\n      mlflow.sklearn.log_model(rf, str(device_id))\n      mlflow.log_metric(\"mse\", mse)\n      \n      artifact_uri = f\"runs:/{run.info.run_id}/{device_id}\"\n      # Create a return pandas DataFrame that matches the schema above\n      returnDF = pd.DataFrame([[device_id, n_used, artifact_uri, mse]], \n        columns=[\"device_id\", \"n_used\", \"model_path\", \"mse\"])\n\n  return returnDF \n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7e9d83a1-5902-42a3-87d8-c6ba2aea924e","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Apply the pandas UDF to grouped data"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c5faa001-2a4c-49f9-abda-8b092dd2b9cc","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["with mlflow.start_run(run_name=\"Training session for all devices\") as run:\n  run_id = run.info.run_id\n  \n  modelDirectoriesDF = (df\n    .withColumn(\"run_id\", f.lit(run_id)) # Add run_id\n    .groupby(\"device_id\")\n    .applyInPandas(train_model, schema=trainReturnSchema)\n  )\n  \ncombinedDF = (df\n  .join(modelDirectoriesDF, on=\"device_id\", how=\"left\")\n)\n\ndisplay(combinedDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"65bea4c9-8b12-4562-b670-5acabd648e39","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Define a pandas UDF to apply the model.  *This needs only one read from DBFS per device.*"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"54270391-b768-4709-879f-ebb005eaa095","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["applyReturnSchema = t.StructType([\n  t.StructField(\"record_id\", t.IntegerType()),\n  t.StructField(\"prediction\", t.FloatType())\n])\n\ndef apply_model(df_pandas: pd.DataFrame) -> pd.DataFrame:\n  \"\"\"\n  Applies model to data for a particular device, represented as a pandas DataFrame\n  \"\"\"\n  model_path = df_pandas[\"model_path\"].iloc[0]\n  \n  input_columns = [\"feature_1\", \"feature_2\", \"feature_3\"]\n  X = df_pandas[input_columns]\n  \n  model = mlflow.sklearn.load_model(model_path)\n  prediction = model.predict(X)\n  \n  returnDF = pd.DataFrame({\n    \"record_id\": df_pandas[\"record_id\"],\n    \"prediction\": prediction\n  })\n  return returnDF\n\npredictionDF = combinedDF.groupby(\"device_id\").applyInPandas(apply_model, schema=applyReturnSchema)\ndisplay(predictionDF)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"53d81ed8-1a09-4dd6-a36f-0040b3251b49","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n&copy; 2020 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c26efef8-9b9a-495a-b276-b65189fc0b66","inputWidgets":{},"title":""}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"11b_Training_Pandas_UDFs","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":74902913649672}},"nbformat":4,"nbformat_minor":0}
