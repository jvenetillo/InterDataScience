{"cells":[{"cell_type":"markdown","source":["## [Clustering with Spark](https://spark.apache.org/docs/latest/ml-clustering.html)  \n\nThis notebook describes clustering algorithms in Spark MLlib.  \nThe guide for clustering in the RDD-based API also has relevant information about these algorithms.\n\n### Table of Contents\n\n+ K-means\n+ Input Columns\n+ Output Columns\n+ Latent Dirichlet allocation (LDA)\n+ Bisecting k-means\n+ Gaussian Mixture Model (GMM)\n+ Input Columns\n+ Output Columns\n+ Power Iteration Clustering (PIC)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"814fe9cf-3d54-41c4-b564-f835bd974b13","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["#### [K-means](https://github.com/apache/spark/blob/master/examples/src/main/python/mllib/k_means_example.py)  \n\n[k-means](http://en.wikipedia.org/wiki/K-means_clustering) is one of the most commonly used clustering algorithms that clusters the data points into a predefined number of clusters. The MLlib implementation includes a parallelized variant of the k-means++ method called kmeans||.\n\nKMeans is implemented as an Estimator and generates a KMeansModel as the base model.\n\n\n<h3 id=\"input-columns\">Input Columns</h3>\n\n<table class=\"table\">\n  <thead>\n    <tr>\n      <th align=\"left\">Param name</th>\n      <th align=\"left\">Type(s)</th>\n      <th align=\"left\">Default</th>\n      <th align=\"left\">Description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>featuresCol</td>\n      <td>Vector</td>\n      <td>\"features\"</td>\n      <td>Feature vector</td>\n    </tr>\n  </tbody>\n</table>\n\n<h3 id=\"output-columns\">Output Columns</h3>\n\n<table class=\"table\">\n  <thead>\n    <tr>\n      <th align=\"left\">Param name</th>\n      <th align=\"left\">Type(s)</th>\n      <th align=\"left\">Default</th>\n      <th align=\"left\">Description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>predictionCol</td>\n      <td>Int</td>\n      <td>\"prediction\"</td>\n      <td>Predicted cluster center</td>\n    </tr>\n  </tbody>\n</table>"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fc121405-328c-4951-86db-a2961cb0308b","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import os\nos.getcwd()\n\n# Notes on reading files for Spark within Databricks\n# https://docs.databricks.com/_static/notebooks/files-in-repos.html"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"539af09e-8a3f-4c42-be25-1fe2e12327c3","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[1]: '/Workspace/Repos/renato.rocha-souza@rbinternational.com/Embedded_Data_Scientist/Module_B/Day3'","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[1]: '/Workspace/Repos/renato.rocha-souza@rbinternational.com/Embedded_Data_Scientist/Module_B/Day3'"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.ml.clustering import KMeans\nfrom pyspark.ml.evaluation import ClusteringEvaluator\n\n# Loads data.\ndataset = spark.read.format(\"libsvm\").load(f\"file:{os.getcwd()}/data/mllib/sample_kmeans_data.txt\")\n\n# Trains a k-means model.\nkmeans = KMeans().setK(2).setSeed(1)\nmodel = kmeans.fit(dataset)\n\n# Make predictions\npredictions = model.transform(dataset)\n\n# Evaluate clustering by computing Silhouette score\nevaluator = ClusteringEvaluator()\n\nsilhouette = evaluator.evaluate(predictions)\nprint(\"Silhouette with squared euclidean distance = \" + str(silhouette))\n\n# Shows the result.\ncenters = model.clusterCenters()\nprint(\"Cluster Centers: \")\nfor center in centers:\n    print(center)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"dffdc758-f163-485f-b1de-55a790d9b624","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Silhouette with squared euclidean distance = 0.9997530305375207\nCluster Centers: \n[9.1 9.1 9.1]\n[0.1 0.1 0.1]\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Silhouette with squared euclidean distance = 0.9997530305375207\nCluster Centers: \n[9.1 9.1 9.1]\n[0.1 0.1 0.1]\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### [Latent Dirichlet allocation (LDA)](https://github.com/apache/spark/blob/master/examples/src/main/python/ml/lda_example.py)  \n\nLDA is implemented as an Estimator that supports both EMLDAOptimizer and OnlineLDAOptimizer, and generates a LDAModel as the base model.\nExpert users may cast a LDAModel generated by EMLDAOptimizer to a DistributedLDAModel if needed."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9a245abf-9169-4a85-bf2d-3b6944e87072","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.ml.clustering import LDA\n\n# Loads data.\ndataset = spark.read.format(\"libsvm\").load(f\"file:{os.getcwd()}/data/mllib/sample_lda_libsvm_data.txt\")\n\n# Trains a LDA model.\nlda = LDA(k=10, maxIter=10)\nmodel = lda.fit(dataset)\n\nll = model.logLikelihood(dataset)\nlp = model.logPerplexity(dataset)\nprint(\"The lower bound on the log likelihood of the entire corpus: \" + str(ll))\nprint(\"The upper bound on perplexity: \" + str(lp))\n\n# Describe topics.\ntopics = model.describeTopics(3)\nprint(\"The topics described by their top-weighted terms:\")\ntopics.show(truncate=False)\n\n# Shows the result\ntransformed = model.transform(dataset)\ntransformed.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"88b64738-ef67-45a8-9b4c-54966222991e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"The lower bound on the log likelihood of the entire corpus: -797.5200544004555\nThe upper bound on perplexity: 3.0673848246171365\nThe topics described by their top-weighted terms:\n+-----+-----------+---------------------------------------------------------------+\n|topic|termIndices|termWeights                                                    |\n+-----+-----------+---------------------------------------------------------------+\n|0    |[1, 3, 4]  |[0.10368082673401043, 0.10246920001021176, 0.09945342991888821]|\n|1    |[0, 5, 9]  |[0.1076176051626867, 0.09801051465962088, 0.09705006627909334] |\n|2    |[5, 10, 9] |[0.09817190617101527, 0.0981118296756393, 0.09564406780739915] |\n|3    |[5, 10, 2] |[0.10428733568856435, 0.10200642097504846, 0.09787247160826047]|\n|4    |[5, 8, 2]  |[0.10610350651837704, 0.10225089640708551, 0.0969920925809682] |\n|5    |[2, 1, 5]  |[0.1017814308587037, 0.09673789329662605, 0.09602700830858574] |\n|6    |[3, 5, 4]  |[0.1616436533169385, 0.1391919780709568, 0.11423150148553422]  |\n|7    |[8, 3, 5]  |[0.10449091906046457, 0.09702934195910436, 0.09685753582283695]|\n|8    |[2, 10, 5] |[0.20489639898500683, 0.0964903976654958, 0.09642582722801787] |\n|9    |[9, 1, 8]  |[0.10442114834534162, 0.0972521760982583, 0.09678634963629762] |\n+-----+-----------+---------------------------------------------------------------+\n\n+-----+---------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|label|features                                                       |topicDistribution                                                                                                                                                                                                     |\n+-----+---------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|0.0  |(11,[0,1,2,4,5,6,7,10],[1.0,2.0,6.0,2.0,3.0,1.0,1.0,3.0])      |[0.004676952344250045,0.004676968395495595,0.004676950578410848,0.004676970332583484,0.004676967419293877,0.0046769759336480555,0.00586884662388327,0.004676918960470165,0.9567155317134576,0.004676917698507178]     |\n|1.0  |(11,[0,1,3,4,7,10],[1.0,3.0,1.0,3.0,2.0,1.0])                  |[0.007805785111705882,0.007805628378410143,0.007805672976519763,0.007805633036666408,0.0078056512171248245,0.0078057068437358225,0.9296064359680699,0.007805670690530401,0.007948154376537068,0.0078056614006996585]  |\n|2.0  |(11,[0,1,2,5,6,8,9],[1.0,4.0,1.0,4.0,9.0,1.0,2.0])             |[0.004065785807285062,0.004065796483945533,0.004065741735817013,0.004065754454676408,0.004065789124629428,0.004065756363747333,0.9633338428475929,0.004065766920250332,0.004140035607639875,0.004065730654416079]     |\n|3.0  |(11,[0,1,3,6,8,9,10],[2.0,1.0,3.0,5.0,2.0,3.0,9.0])            |[0.003595999611587824,0.0035959934673908856,0.003595986426016544,0.003596001942206489,0.0035960042711613415,0.0035959699075005618,0.9675706109074504,0.0035959527682424314,0.003661498769496744,0.0035959819289466694]|\n|4.0  |(11,[0,1,2,3,4,6,9,10],[3.0,1.0,1.0,9.0,3.0,2.0,1.0,3.0])      |[0.003896056145092278,0.0038960230822260213,0.003896021727591732,0.0038960395775907686,0.0038960305976958186,0.003896041370270874,0.9648646437935958,0.003896005371138772,0.003967131081227989,0.00389600725356977]   |\n|5.0  |(11,[0,1,3,4,5,6,7,8,9],[4.0,2.0,3.0,4.0,5.0,1.0,1.0,1.0,4.0]) |[0.0035958512635438883,0.003595871053475638,0.00359585118699201,0.0035958415673139612,0.0035958614858202405,0.00359585244224661,0.9675718310622518,0.003595862687536621,0.0036613294104646645,0.0035958478403545777]  |\n|6.0  |(11,[0,1,3,6,8,9,10],[2.0,1.0,3.0,5.0,2.0,2.0,9.0])            |[0.0037400901498766165,0.0037400772487206613,0.003740070441270972,0.003740090492304099,0.00374009199048886,0.003740054667297089,0.9662712134927176,0.0037400345829021095,0.0038082130712644995,0.0037400638631574046] |\n|7.0  |(11,[0,1,2,3,4,5,6,9,10],[1.0,1.0,1.0,9.0,2.0,1.0,2.0,1.0,3.0])|[0.004250912590410982,0.004250864880548274,0.004250873025195017,0.004250902392318307,0.004250896259490729,0.004250894608318159,0.9616644557550442,0.004250858331703485,0.004328484876898299,0.0042508572800724845]    |\n|8.0  |(11,[0,1,3,4,5,6,7],[4.0,4.0,3.0,4.0,2.0,1.0,3.0])             |[0.004250932615766632,0.004250898540265684,0.0042508952107341985,0.00425086861721875,0.004250884020041738,0.004250912696613805,0.9616644057735709,0.004250906355026676,0.004328414896664478,0.004250881274096983]     |\n|9.0  |(11,[0,1,2,4,6,8,9,10],[2.0,8.0,2.0,3.0,2.0,2.0,7.0,2.0])      |[0.003223448053600673,0.0032234489591785147,0.0032234166852612113,0.003223426409605953,0.0032234482613675165,0.0032234389423863494,0.9709301695594706,0.003223426508496813,0.003282337187326747,0.003223439433305499] |\n|10.0 |(11,[0,1,2,3,5,6,9,10],[1.0,1.0,1.0,9.0,2.0,2.0,3.0,3.0])      |[0.004065743021552847,0.004065719209428452,0.004065721146442432,0.004065739269769889,0.004065742925579614,0.004065734100893753,0.9633342514366949,0.004065707081142349,0.004139929792297152,0.004065712016198601]     |\n|11.0 |(11,[0,1,4,5,6,7,9],[4.0,1.0,4.0,5.0,1.0,3.0,1.0])             |[0.0046768759999497155,0.00467689354556461,0.00467689400000143,0.00467684536293083,0.004676869638433628,0.004676885773237369,0.9578227095930838,0.004676890777371828,0.004762279954757638,0.004676855354669124]       |\n+-----+---------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["The lower bound on the log likelihood of the entire corpus: -797.5200544004555\nThe upper bound on perplexity: 3.0673848246171365\nThe topics described by their top-weighted terms:\n+-----+-----------+---------------------------------------------------------------+\n|topic|termIndices|termWeights                                                    |\n+-----+-----------+---------------------------------------------------------------+\n|0    |[1, 3, 4]  |[0.10368082673401043, 0.10246920001021176, 0.09945342991888821]|\n|1    |[0, 5, 9]  |[0.1076176051626867, 0.09801051465962088, 0.09705006627909334] |\n|2    |[5, 10, 9] |[0.09817190617101527, 0.0981118296756393, 0.09564406780739915] |\n|3    |[5, 10, 2] |[0.10428733568856435, 0.10200642097504846, 0.09787247160826047]|\n|4    |[5, 8, 2]  |[0.10610350651837704, 0.10225089640708551, 0.0969920925809682] |\n|5    |[2, 1, 5]  |[0.1017814308587037, 0.09673789329662605, 0.09602700830858574] |\n|6    |[3, 5, 4]  |[0.1616436533169385, 0.1391919780709568, 0.11423150148553422]  |\n|7    |[8, 3, 5]  |[0.10449091906046457, 0.09702934195910436, 0.09685753582283695]|\n|8    |[2, 10, 5] |[0.20489639898500683, 0.0964903976654958, 0.09642582722801787] |\n|9    |[9, 1, 8]  |[0.10442114834534162, 0.0972521760982583, 0.09678634963629762] |\n+-----+-----------+---------------------------------------------------------------+\n\n+-----+---------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|label|features                                                       |topicDistribution                                                                                                                                                                                                     |\n+-----+---------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|0.0  |(11,[0,1,2,4,5,6,7,10],[1.0,2.0,6.0,2.0,3.0,1.0,1.0,3.0])      |[0.004676952344250045,0.004676968395495595,0.004676950578410848,0.004676970332583484,0.004676967419293877,0.0046769759336480555,0.00586884662388327,0.004676918960470165,0.9567155317134576,0.004676917698507178]     |\n|1.0  |(11,[0,1,3,4,7,10],[1.0,3.0,1.0,3.0,2.0,1.0])                  |[0.007805785111705882,0.007805628378410143,0.007805672976519763,0.007805633036666408,0.0078056512171248245,0.0078057068437358225,0.9296064359680699,0.007805670690530401,0.007948154376537068,0.0078056614006996585]  |\n|2.0  |(11,[0,1,2,5,6,8,9],[1.0,4.0,1.0,4.0,9.0,1.0,2.0])             |[0.004065785807285062,0.004065796483945533,0.004065741735817013,0.004065754454676408,0.004065789124629428,0.004065756363747333,0.9633338428475929,0.004065766920250332,0.004140035607639875,0.004065730654416079]     |\n|3.0  |(11,[0,1,3,6,8,9,10],[2.0,1.0,3.0,5.0,2.0,3.0,9.0])            |[0.003595999611587824,0.0035959934673908856,0.003595986426016544,0.003596001942206489,0.0035960042711613415,0.0035959699075005618,0.9675706109074504,0.0035959527682424314,0.003661498769496744,0.0035959819289466694]|\n|4.0  |(11,[0,1,2,3,4,6,9,10],[3.0,1.0,1.0,9.0,3.0,2.0,1.0,3.0])      |[0.003896056145092278,0.0038960230822260213,0.003896021727591732,0.0038960395775907686,0.0038960305976958186,0.003896041370270874,0.9648646437935958,0.003896005371138772,0.003967131081227989,0.00389600725356977]   |\n|5.0  |(11,[0,1,3,4,5,6,7,8,9],[4.0,2.0,3.0,4.0,5.0,1.0,1.0,1.0,4.0]) |[0.0035958512635438883,0.003595871053475638,0.00359585118699201,0.0035958415673139612,0.0035958614858202405,0.00359585244224661,0.9675718310622518,0.003595862687536621,0.0036613294104646645,0.0035958478403545777]  |\n|6.0  |(11,[0,1,3,6,8,9,10],[2.0,1.0,3.0,5.0,2.0,2.0,9.0])            |[0.0037400901498766165,0.0037400772487206613,0.003740070441270972,0.003740090492304099,0.00374009199048886,0.003740054667297089,0.9662712134927176,0.0037400345829021095,0.0038082130712644995,0.0037400638631574046] |\n|7.0  |(11,[0,1,2,3,4,5,6,9,10],[1.0,1.0,1.0,9.0,2.0,1.0,2.0,1.0,3.0])|[0.004250912590410982,0.004250864880548274,0.004250873025195017,0.004250902392318307,0.004250896259490729,0.004250894608318159,0.9616644557550442,0.004250858331703485,0.004328484876898299,0.0042508572800724845]    |\n|8.0  |(11,[0,1,3,4,5,6,7],[4.0,4.0,3.0,4.0,2.0,1.0,3.0])             |[0.004250932615766632,0.004250898540265684,0.0042508952107341985,0.00425086861721875,0.004250884020041738,0.004250912696613805,0.9616644057735709,0.004250906355026676,0.004328414896664478,0.004250881274096983]     |\n|9.0  |(11,[0,1,2,4,6,8,9,10],[2.0,8.0,2.0,3.0,2.0,2.0,7.0,2.0])      |[0.003223448053600673,0.0032234489591785147,0.0032234166852612113,0.003223426409605953,0.0032234482613675165,0.0032234389423863494,0.9709301695594706,0.003223426508496813,0.003282337187326747,0.003223439433305499] |\n|10.0 |(11,[0,1,2,3,5,6,9,10],[1.0,1.0,1.0,9.0,2.0,2.0,3.0,3.0])      |[0.004065743021552847,0.004065719209428452,0.004065721146442432,0.004065739269769889,0.004065742925579614,0.004065734100893753,0.9633342514366949,0.004065707081142349,0.004139929792297152,0.004065712016198601]     |\n|11.0 |(11,[0,1,4,5,6,7,9],[4.0,1.0,4.0,5.0,1.0,3.0,1.0])             |[0.0046768759999497155,0.00467689354556461,0.00467689400000143,0.00467684536293083,0.004676869638433628,0.004676885773237369,0.9578227095930838,0.004676890777371828,0.004762279954757638,0.004676855354669124]       |\n+-----+---------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### [Bisecting k-means](https://github.com/apache/spark/blob/master/examples/src/main/python/ml/bisecting_k_means_example.py)\n\nBisecting k-means is a kind of [hierarchical clustering](https://en.wikipedia.org/wiki/Hierarchical_clustering) using a divisive (or “top-down”) approach: all observations start in one cluster, and splits are performed recursively as one moves down the hierarchy.  \n\nBisecting K-means can often be much faster than regular K-means, but it will generally produce a different clustering.  \n\nBisectingKMeans is implemented as an Estimator and generates a BisectingKMeansModel as the base model."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d4fa88a2-49a2-44db-924b-c2819f91ba7f","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.ml.clustering import BisectingKMeans\nfrom pyspark.ml.evaluation import ClusteringEvaluator\n\n# Loads data.\ndataset = spark.read.format(\"libsvm\").load(f\"file:{os.getcwd()}/data/mllib/sample_kmeans_data.txt\")\n\n# Trains a bisecting k-means model.\nbkm = BisectingKMeans().setK(2).setSeed(1)\nmodel = bkm.fit(dataset)\n\n# Make predictions\npredictions = model.transform(dataset)\n\n# Evaluate clustering by computing Silhouette score\nevaluator = ClusteringEvaluator()\n\nsilhouette = evaluator.evaluate(predictions)\nprint(\"Silhouette with squared euclidean distance = \" + str(silhouette))\n\n# Shows the result.\nprint(\"Cluster Centers: \")\ncenters = model.clusterCenters()\nfor center in centers:\n    print(center)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ccd916cc-5924-4666-97ce-af561907f115","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Silhouette with squared euclidean distance = 0.9997530305375207\nCluster Centers: \n[0.1 0.1 0.1]\n[9.1 9.1 9.1]\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Silhouette with squared euclidean distance = 0.9997530305375207\nCluster Centers: \n[0.1 0.1 0.1]\n[9.1 9.1 9.1]\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### [Gaussian Mixture Model (GMM)](https://github.com/apache/spark/blob/master/examples/src/main/python/ml/gaussian_mixture_example.py)\n\nA [Gaussian Mixture Model](http://en.wikipedia.org/wiki/Mixture_model#Multivariate_Gaussian_mixture_model) represents a composite distribution whereby points are drawn from one of k Gaussian sub-distributions, each with its own probability.  \nThe spark.ml implementation uses the [expectation-maximization](http://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm) algorithm to induce the maximum-likelihood model given a set of samples.  \n\nGaussianMixture is implemented as an Estimator and generates a GaussianMixtureModel as the base model.  \n\n<h3 id=\"input-columns-1\">Input Columns</h3>\n\n<table class=\"table\">\n  <thead>\n    <tr>\n      <th align=\"left\">Param name</th>\n      <th align=\"left\">Type(s)</th>\n      <th align=\"left\">Default</th>\n      <th align=\"left\">Description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>featuresCol</td>\n      <td>Vector</td>\n      <td>\"features\"</td>\n      <td>Feature vector</td>\n    </tr>\n  </tbody>\n</table>\n\n<h3 id=\"output-columns-1\">Output Columns</h3>\n\n<table class=\"table\">\n  <thead>\n    <tr>\n      <th align=\"left\">Param name</th>\n      <th align=\"left\">Type(s)</th>\n      <th align=\"left\">Default</th>\n      <th align=\"left\">Description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>predictionCol</td>\n      <td>Int</td>\n      <td>\"prediction\"</td>\n      <td>Predicted cluster center</td>\n    </tr>\n    <tr>\n      <td>probabilityCol</td>\n      <td>Vector</td>\n      <td>\"probability\"</td>\n      <td>Probability of each cluster</td>\n    </tr>\n  </tbody>\n</table>"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"be2d365a-0dae-4cc8-b29e-d994db8b1fa7","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.ml.clustering import GaussianMixture\n\n# loads data\ndataset = spark.read.format(\"libsvm\").load(f\"file:{os.getcwd()}/data/mllib/sample_kmeans_data.txt\")\n\ngmm = GaussianMixture().setK(2).setSeed(538009335)\nmodel = gmm.fit(dataset)\n\nprint(\"Gaussians shown as a DataFrame: \")\nmodel.gaussiansDF.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0356d52f-9676-40e7-8108-c4440772af14","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Gaussians shown as a DataFrame: \n+-------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|mean                                                         |cov                                                                                                                                                                                                       |\n+-------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|[0.10000000000001552,0.10000000000001552,0.10000000000001552]|0.006666666666806454  0.006666666666806454  0.006666666666806454  \\n0.006666666666806454  0.006666666666806454  0.006666666666806454  \\n0.006666666666806454  0.006666666666806454  0.006666666666806454  |\n|[9.099999999999984,9.099999999999984,9.099999999999984]      |0.006666666666812185  0.006666666666812185  0.006666666666812185  \\n0.006666666666812185  0.006666666666812185  0.006666666666812185  \\n0.006666666666812185  0.006666666666812185  0.006666666666812185  |\n+-------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Gaussians shown as a DataFrame: \n+-------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|mean                                                         |cov                                                                                                                                                                                                       |\n+-------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|[0.10000000000001552,0.10000000000001552,0.10000000000001552]|0.006666666666806454  0.006666666666806454  0.006666666666806454  \\n0.006666666666806454  0.006666666666806454  0.006666666666806454  \\n0.006666666666806454  0.006666666666806454  0.006666666666806454  |\n|[9.099999999999984,9.099999999999984,9.099999999999984]      |0.006666666666812185  0.006666666666812185  0.006666666666812185  \\n0.006666666666812185  0.006666666666812185  0.006666666666812185  \\n0.006666666666812185  0.006666666666812185  0.006666666666812185  |\n+-------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### [Power Iteration Clustering (PIC)](https://github.com/apache/spark/blob/master/examples/src/main/python/ml/power_iteration_clustering_example.py)\n\nPower Iteration Clustering (PIC) is a scalable graph clustering algorithm developed by [Lin and Cohen](http://www.cs.cmu.edu/~frank/papers/icml2010-pic-final.pdf). From the abstract: PIC finds a very low-dimensional embedding of a dataset using truncated power iteration on a normalized pair-wise similarity matrix of the data.\n\nspark.ml’s PowerIterationClustering implementation takes the following parameters:\n\n+ k: the number of clusters to create\n+ initMode: param for the initialization algorithm\n+ maxIter: param for maximum number of iterations\n+ srcCol: param for the name of the input column for source vertex IDs\n+ dstCol: name of the input column for destination vertex IDs\n+ weightCol: Param for weight column name"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6ca4f5c4-9df8-45ad-99d3-919696e7a081","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.ml.clustering import PowerIterationClustering\n\ndf = spark.createDataFrame([\n    (0, 1, 1.0),\n    (0, 2, 1.0),\n    (1, 2, 1.0),\n    (3, 4, 1.0),\n    (4, 0, 0.1)\n], [\"src\", \"dst\", \"weight\"])\n\npic = PowerIterationClustering(k=2, maxIter=20, initMode=\"degree\", weightCol=\"weight\")\n\n# Shows the cluster assignment\npic.assignClusters(df).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6a604384-3b05-4073-a149-03af5c72f0af","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---+-------+\n| id|cluster|\n+---+-------+\n|  4|      0|\n|  0|      1|\n|  1|      1|\n|  2|      1|\n|  3|      0|\n+---+-------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+-------+\n| id|cluster|\n+---+-------+\n|  4|      0|\n|  0|      1|\n|  1|      1|\n|  2|      1|\n|  3|      0|\n+---+-------+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["Licensed to the Apache Software Foundation (ASF) under one or more\ncontributor license agreements.  See the NOTICE file distributed with\nthis work for additional information regarding copyright ownership.\nThe ASF licenses this file to You under the Apache License, Version 2.0\n(the \"License\"); you may not use this file except in compliance with\nthe License.  You may obtain a copy of the License at\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"63a4e462-d84e-4956-8d58-517e6d083e7e","inputWidgets":{},"title":""}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"08_Clustering_with_Spark","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":1059930657351577}},"nbformat":4,"nbformat_minor":0}
