{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Processing Notebook\n",
    "In this task, you will get a sense of using Python to do **text processing**. The dataset that we have is a public collection of SMS messages that have been collected for mobile phone spam reserach. <br>\n",
    "The **goal** is: based on the text in the sms message to predict whether the message is a spam or not.\n",
    "\n",
    "\n",
    "## Dataset Information\n",
    "We have the same set of data in two file formats: csv and txt file. Baesd on your preference, you can choose one file format to work with ðŸ˜Š. <br>\n",
    "The dataset consists of a collection of different sms messages, with each line consisted of one label (either ham or spam) and the raw message. \n",
    "\n",
    "**See some examples below:** <br>\n",
    "ham What you doing?how are you? <br>\n",
    "ham Ok lar... Joking wif u oni... <br>\n",
    "ham dun say so early hor... U c already then say... <br>\n",
    "ham MY NO. IN LUTON 0125698789 RING ME IF UR AROUND! H*<br>\n",
    "ham Siva is in hostel aha:-.<br>\n",
    "ham Cos i was out shopping wif darren jus now n i called him 2 ask wat present he wan lor. Then he started guessing who i was wif n he finally guessed darren lor.<br>\n",
    "spam FreeMsg: Txt: CALL to No: 86888 & claim your reward of 3 hours talk time to use from your phone now! ubscribe6GBP/ mnth inc 3hrs 16 stop?txtStop<br>\n",
    "spam Sunshine Quiz! Win a super Sony DVD recorder if you canname the capital of Australia? Text MQUIZ to 82277. B<br>\n",
    "spam URGENT! Your Mobile No 07808726822 was awarded a L2,000 Bonus Caller Prize on 02/09/03! This is our 2nd attempt to contact YOU! Call 0871-872-9758 BOX95QU<br>\n",
    "\n",
    "Note: the messages are not chronologically sorted.\n",
    "\n",
    "Dataset Citation:http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/\n",
    "The SMS Spam Collection has been created by [Tiago A. Almeida](http://dcomp.sor.ufscar.br/talmeida/) and [JosÃ© MarÃ­a GÃ³mez Hidalgo](http://www.esp.uem.es/jmgomez)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Text Processing\n",
    "The steps below are served as a guidance to solve this text processing problem. They are by no means a must or the only way to solve this partcular dataset. Feel free to use what you have learned in the previous program and to be creative. Try to find out your own approach to this problem.\n",
    "\n",
    "1. **Step 1: Data loading & preprocessing**\n",
    "    - load the data into Python Notebook and convert it to the appropriate format (dataframe, numpy.array, list, etc.)\n",
    "    - observe & explore the dataset, take a look at its structure\n",
    "\n",
    "2. **Step 2: Text normalization**\n",
    "    - convert all letters to lower case\n",
    "    - convert numbers into words and remove all numbers\n",
    "    - remove punctuations, accent marks, or other diacritics\n",
    "    - remove all white spaces\n",
    "    - expand abbreviations\n",
    "    - remove stop words, and other particular unnecessary words\n",
    "    - text canonicalization\n",
    "       \n",
    "2. **Step 3: Data modelling**\n",
    "    - separate the label and the raw messages \n",
    "    - split dataset into training & testing dataset\n",
    "    - pick one data modelling approach respectively the Python modelling package that you would like to use\n",
    "    - fit the training dataset to the model and train the model\n",
    "    - output the model \n",
    "    - make prediction on testing dataset\n",
    "\n",
    "3. **Step 3: Fine tune the model for a better result**\n",
    "    - map the prediction of the testing dataset against real numbers from your dataset and compare the result\n",
    "    - make adjustments on your model for a better result (but make sure don't overfit the model)\n",
    "    \n",
    "4. **Step 4: Result extration & interpretation**\n",
    "    - make your conclusions and interpretation on the model and final results\n",
    "    - evaluate the performance of your model and algorithm using different KPIs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Resources:\n",
    "- the text processing that we are doing here evolves natural languagae process, you can take a look at here: https://en.wikipedia.org/wiki/Natural_language_processing\n",
    "- to learn more about stemming and lemmatization: https://www.datacamp.com/community/tutorials/stemming-lemmatization-python\n",
    "- what are stop words: https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
    "- text normalization: https://en.wikipedia.org/wiki/Text_normalization\n",
    "\n",
    "**Useful links:**\n",
    "- https://medium.com/@datamonsters/text-preprocessing-in-python-steps-tools-and-examples-bf025f872908\n",
    "- https://towardsdatascience.com/spam-or-ham-introduction-to-natural-language-processing-part-2-a0093185aebd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
