{"cells":[{"cell_type":"markdown","source":["# Data Science workflow  \n\nIn this sequence of notebooks, we will exemplify the inner steps in the Data Science workflow.  \nWe are not going to discuss the business requirements and deployment strategies, but just the phases below:\n\n### I - Exploratory Data Analysis (this notebook)  \n##### II - Feature Engineering and Selection \n##### III - Modeling  \n##### IV - Evaluation  \n\nThis notebook will cover the Exploratory Data Analysis (EDA)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f9803404-d89f-4195-bb02-9cf515ccdca9"}}},{"cell_type":"markdown","source":["## I - Exploratory Data Analysis  \n\nExploratory Data Analysis is a set of techniques that were developed by John Wilder Tukey in 1970. The philosophy behind this approach was to examine the data before building a model.  \nJohn Tukey encouraged statisticians to explore the data, and possibly formulate hypotheses that could lead to new data collection and experiments.  \n\nToday Data scientists and analysts spend most of their time in Data Wrangling and Exploratory Data Analysis also known as EDA. But what is this EDA and why it is so important? \nExploratory Data Analysis (EDA) is a step in the Data Science Workflow, where a number of techniques are used to better understand the dataset being used.\n\n‘Understanding the dataset’ can refer to a number of things including but not limited to…\n\n+ Get maximum insights from a data set\n+ Uncover underlying structure\n+ Extracting important variables and leaving behind useless variables\n+ Identifying outliers, anomalies, missing values, or human error\n+ Understanding the relationship(s), or lack of, between variables\n+ Test underlying assumptions\n+ Ultimately, maximizing your insights of a dataset and minimizing potential error that may occur later in the process"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fd2e248b-af8f-4df2-8d01-9364512c195d"}}},{"cell_type":"markdown","source":["##### Let's see how exploratory data analysis is regarded in CRISP-DM and CRISP-ML:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9f70c8cd-850d-4201-adc7-c5e78326ecd9"}}},{"cell_type":"markdown","source":["## CRISP-DM\n\nThe CRoss Industry Standard Process for Data Mining ([CRISP-DM](https://www.datascience-pm.com/crisp-dm-2/)) is a process model that serves as the base for a data science process. \n\nIt has six sequential phases:\n\n+ Business understanding – What does the business need?\n+ Data understanding – What data do we have / need? Is it clean?\n+ Data preparation – How do we organize the data for modeling?\n+ Modeling – What modeling techniques should we apply?\n+ Evaluation – Which model best meets the business objectives?\n+ Deployment – How do stakeholders access the results?\n\n\n[CRISP-DM Process](https://miro.medium.com/max/736/1*0-mnwXXLlMB_bEQwp-706Q.png)\n\n<br>\n<img src=\"https://miro.medium.com/max/736/1*0-mnwXXLlMB_bEQwp-706Q.png\" width=\"768\" height=\"512\" />"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c5d74bb6-38c3-49d0-bca3-62dc6a7d96d7"}}},{"cell_type":"markdown","source":["The machine learning community is still trying to establish a standard process model for machine learning development. As a result, many machine learning and data science projects are still not well organized. Results are not reproducible.  \nIn general, such projects are conducted in an ad-hoc manner. To guide ML practitioners through the development life cycle, the Cross-Industry Standard Process for the development of Machine Learning applications with Quality assurance methodology ([CRISP-ML(Q)](https://ml-ops.org/content/crisp-ml)) was recently proposed.  \n\nThere is a particular order of the individual stages. Still, machine learning workflows are fundamentally iterative and exploratory, so that depending on the results from the later phases, we might re-examine earlier steps."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9b2a8d77-6cbd-4160-8741-c1c1685fe42b"}}},{"cell_type":"markdown","source":["## CRISP-ML\n\n[CRISP-ML Process](https://ml-ops.org/img/crisp-ml-process.jpg)  \n[Source](https://ml-ops.org/content/crisp-ml)\n\n<br>\n<img src=\"https://ml-ops.org/img/crisp-ml-process.jpg\" width=\"1024\" height=\"512\" />"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7f2fb199-2689-43c3-8d9d-d0e9b105ebff"}}},{"cell_type":"markdown","source":["If we explode the EDA phase in each of the previous frameworks, we would have something like this:\n\n[EDA](https://www.researchgate.net/publication/329930775/figure/fig3/AS:873046667710469@1585161954284/The-fundamental-steps-of-the-exploratory-data-analysis-process_W640.jpg)  \n[Source](https://www.researchgate.net/publication/329930775_A_comprehensive_review_of_tools_for_exploratory_analysis_of_tabular_industrial_datasets)\n\n<br>\n<img src=\"https://www.researchgate.net/publication/329930775/figure/fig3/AS:873046667710469@1585161954284/The-fundamental-steps-of-the-exploratory-data-analysis-process_W640.jpg\" width=\"1024\" height=\"512\" />"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d954d2ac-69c4-4cde-b982-ce3026a0c2fe"}}},{"cell_type":"markdown","source":["### Starting the EDA"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"01e131b7-ceab-4936-875a-2a0a8e1878d0"}}},{"cell_type":"markdown","source":["### 1. Import libraries"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5c6f5b3f-4ab6-4b90-9f82-0ae50089f0c3"}}},{"cell_type":"code","source":["import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns #https://towardsdatascience.com/a-major-seaborn-plotting-tip-i-wish-i-had-learned-earlier-d8209ad0a20e\nimport pandas as pd"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ffb8430b-4d79-4be5-bae5-84b31c75e6a2"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 2. Load Dataset and Distinguishing Attributes"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ba73e5e2-bd75-4f80-91ab-7c1c34f54579"}}},{"cell_type":"markdown","source":["##### 2.1 - Visually inspecting the dataset"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1d60f92f-6c13-43ab-b5e5-c1b7f18d2bc1"}}},{"cell_type":"code","source":["df = pd.read_csv('Data/Automobile_data.csv')\ndf.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"be4593d4-8546-43f7-973b-6d36f4ffb444"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### 2.2 - Checking columns and data types"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"644cf05d-7e06-4947-aef8-4b1ed46b8145"}}},{"cell_type":"code","source":["#df.columns\ndf.info(verbose=True, show_counts=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"838b1e15-0c15-4c0b-804c-6610b939bb63"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### 2.3 - Checking basic statistics - first insight on distributions"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c80ab35a-65e6-4168-b05b-c8416c366b63"}}},{"cell_type":"code","source":["df.describe()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d0a8baf5-1f09-4e6a-bcb0-0376aab3eed6"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### At this moment, you look for columns that shall be transformed/converted later in the workflow."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1db302ed-aacb-42bf-a8fb-a3e42ad76b46"}}},{"cell_type":"code","source":["print(df.select_dtypes(include='number').columns)\nprint(df.select_dtypes(include='object').columns)\nprint(df.select_dtypes(include='category').columns)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dc604148-257e-444b-8d5b-c7ab9b596f2d"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 3. Check for missing values"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aee1eada-aaca-4a17-8c87-f035c90e2d1d"}}},{"cell_type":"code","source":["df.isnull().sum()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"037a25fb-4896-4186-b266-87ee4545a53a"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["It seems there are not missing values, but that may be misleading. Let's explore a bit more:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d807ab31-a4c9-4e05-92d3-204481e247dc"}}},{"cell_type":"code","source":["#Checking for wrong entries like symbols -,?,#,*,etc.\nfor col in df.columns:\n    print('{} : {}'.format(col, df[col].unique()))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3236769e-4551-4364-bf3b-d5c5cb7559d5"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["There are null values in our dataset in form of ‘?’ only but Pandas is not recognizing them so we will replace them into np.nan form."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7042c639-c818-4af0-a314-889bebdf5a3c"}}},{"cell_type":"code","source":["for col in df.columns:\n    df[col].replace({'?': np.nan},inplace=True)\n    \ndf.info()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b4ea51bf-51ea-41e8-9b50-e77c92f40506"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df.isnull().sum()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b9a33a09-60ed-4567-ba2a-fb52263446dc"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### 3.1 Visualizing the missing values  \nNow the missing values are identified in the dataframe. With the help of heatmap, we can see the amount of data that is missing from the attribute. With this, we can make decisions whether to drop these missing values or to replace them. Usually dropping the missing values is not advisable but sometimes it may be helpful too."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6de9c70d-9177-469c-852b-b07a479e59e1"}}},{"cell_type":"code","source":["plt.figure(figsize=(12,10))\nsns.heatmap(df.isnull(),cbar=False,cmap='viridis')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f1ad9a04-9ef9-4565-877f-3447dc47ee78"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Now observe that there are many missing values in normalized_losses while other columns have fewer missing values. We can’t drop the normalized_losses column as it may be important for our prediction.  \nWe can also use the **missingno** libray for a better evaluation of the missing values. First we can check the quantity and how they distribute among the rows:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"089e740c-ee71-458f-949f-ca6e9fd66944"}}},{"cell_type":"code","source":["#!pip install missingno"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d97fe344-fdca-4c51-84ba-1c86f280b2bc"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["import missingno as msno"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6f6d2252-ba64-40db-92b1-d5d29a0ac590"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["msno.bar(df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4ac23c99-8236-4a15-8adf-86636fcef49e"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["msno.matrix(df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f919e3e9-758c-4645-beec-a403c15ac70e"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["The missingno correlation heatmap measures nullity correlation: how strongly the presence or absence of one variable affects the presence of another"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cddb82cf-0d7b-4268-bcf2-31d9c55ca328"}}},{"cell_type":"code","source":["msno.heatmap(df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c395906f-01b6-4349-bf15-cab444108733"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["The dendrogram allows you to more fully correlate variable completion, revealing trends deeper than the pairwise ones visible in the correlation heatmap"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b0715a09-c8b5-4db5-af03-0d6d43e5f420"}}},{"cell_type":"code","source":["msno.dendrogram(df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"56ceae58-1593-4091-9426-7aad9f50d9c6"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### 3.2. Replacing the missing values\nWe will be replacing these missing values with mean because the number of missing values is not great (we could have used the median too).  \nLater, in the data preparation phase, we will learn other imputation techniques."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"60d4effe-1db7-45f6-8d0f-8a3867495f13"}}},{"cell_type":"code","source":["df.select_dtypes(include='number').head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"47b07ab4-5f8a-4701-b8ba-4a819124530c"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df.select_dtypes(include='object').head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6c74a637-dfd2-4b01-a382-d3c543df69e5"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Now let's transform the mistaken datatypes for numeric values and fill with the mean, using the strategy we have chosen."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8df49f92-3c20-414a-bc73-c040c2ec4035"}}},{"cell_type":"code","source":["num_col = ['normalized-losses', 'bore',  'stroke', 'horsepower', 'peak-rpm','price']\nfor col in num_col:\n    df[col] = pd.to_numeric(df[col])\n    df[col].fillna(df[col].mean(), inplace=True)\ndf.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e107147a-d08e-4580-a1f5-a5c1ea899829"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 4. Checking Data Distributions\n\nThis is the most important step in EDA. \n- This step will decide how much insight you can get.\n- Checking the distributions is fundamental for feature selection and the modeling phase\n- This step varies from person to person in terms of their questioning ability. \n\nLet's check the univariate and bivariate distributions and correlation between different variables, this will give us a roadmap on how to proceed further."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a57b0275-4716-4e9b-8bcb-291b807d7b70"}}},{"cell_type":"markdown","source":["#### 4.1 Univariate Analysis  \n\nThe goal here is just to check the distribution of numeric and categorical variables (more about this later in the course)  \nWe can quickly check the distributions of every numeric column:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c4a4ab60-cc33-4921-9569-d25bb7771690"}}},{"cell_type":"code","source":["numeric_cols = df.select_dtypes(include='number').columns\nnumeric_cols"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4592d93f-3528-42ef-b64b-2254be06fdb0"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["for col in numeric_cols:\n    plt.figure(figsize=(18,5))\n    plt.subplot(1,2,1)\n    #sns.distplot(df[col])\n    sns.histplot(df[col], kde=True)\n    plt.subplot(1,2,2)\n    sns.boxplot(x=col, data=df)\n    plt.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"30a693b2-7d2e-4779-9288-009e07da0551"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### 4.1.1 - Analizing distributions on numerical variables - Spotting outliers\n\n![Outliers](https://sphweb.bumc.bu.edu/otlt/MPH-Modules/PH717-QuantCore/PH717-Module6-RandomError/Normal%20Distribution%20deviations.png)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7d37315c-4c7c-4c58-b020-cd58c99ab32a"}}},{"cell_type":"markdown","source":["Assuming the data would follow a normal distribution, we can choose some of the graphs to examine in more detail:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b3e77e6d-dec4-40fb-acbe-c09f8e11e7e6"}}},{"cell_type":"code","source":["#set the style we wish to use for our plots\nsns.set_style(\"darkgrid\")\n\n#plot the distribution of the DataFrame \"Price\" column\nplt.figure(figsize=(8,12))\n#sns.histplot(df['price'])\nsns.displot(df['peak-rpm'], kde=True, bins=50, height=8, aspect=2)  "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"63d87e99-71c7-49ec-9191-c94bc1e7cc8f"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["fig, ax = plt.subplots(figsize=(16,8))\nsns.boxplot(x=\"peak-rpm\", data=df, ax=ax)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"746c8ef9-0806-421b-bb83-42dcb0b76f59"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["We will not treat outliers during Exploratory Data Analysis, but we will get back to them in the Data Preparation phase."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d10c460d-06a6-420a-be10-ff6992588fbb"}}},{"cell_type":"markdown","source":["##### 4.1.2 - Analizing distributions on categorical variables"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f1436ada-9de2-4e44-af78-cb84ee047006"}}},{"cell_type":"markdown","source":["Although it is not one of the recommended plots, we can always use the pie plots in special situations:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e6f6ff50-eaf8-4e55-ba3f-103843b704b4"}}},{"cell_type":"code","source":["fig, ax = plt.subplots(figsize=(8,8))\nplt.pie(df[\"body-style\"].value_counts(sort=False), labels=df[\"body-style\"].unique())\nplt.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a06ae0e7-80b4-4aa1-89ff-bae80e8f1edc"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Barplots with frequencies can be created on Matplotlib"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c7a0c1d5-1e1c-49a0-95f4-2877bd87e786"}}},{"cell_type":"code","source":["df[\"body-style\"].value_counts().plot(kind=\"bar\", figsize=(10,6))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ecff37c0-098b-4ccf-bec8-e6ca6975cfdc"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["There is no need to separately calculate the count when using the sns.countplot() function"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"99a2ffb4-63ad-4a4c-a783-f6062f613370"}}},{"cell_type":"code","source":["fig, ax = plt.subplots(figsize=(12,8))\nsns.countplot(df[\"body-style\"], ax=ax) "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"730b6647-3778-413c-9f91-a8647d362025"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### 4.2 Bivariate Analysis  \n\nNow we want to check the relationships between pais of variables. We can start by drawing a pairplot and a correlation plot."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4129eb5c-79bb-433d-b7ea-ec6442658f4a"}}},{"cell_type":"code","source":["plt.figure(figsize=(10,10))\nsns.pairplot(df.select_dtypes(include='number'))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"118dda9c-a825-4a3d-8026-20ba0630d652"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["The pairplot can help us gaining quick insights on the correlations of variables, but can get cluttered if we have many features.  \nWe can also try the heatmap of correlations:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"87078732-d68d-4a0a-bd3c-eb1e8c87376f"}}},{"cell_type":"code","source":["plt.figure(figsize=(12,12))\nsns.heatmap(df.corr(), cbar=True, annot=True, cmap='Blues')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1a5b3067-c0a9-47ec-821f-5078fff12220"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### Positive Correlation  \n+ Price – wheel_base, length, width, curb_weight, engine_size, bore, horsepower  \n+ wheelbase – length, width, height, curb_weight, engine_size, price  \n+ horsepower – length, width, curb_weight, engine_size, bore, price  \n+ Highway mpg – city mpg  \n\n##### Negative Correlation  \n+ Price – highway_mpg, city_mpg  \n+ highway_mpg – wheel base, length, width, curb_weight, engine_size, bore, horsepower, price  \n+ city – wheel base, length, width, curb_weight, engine_size, bore, horsepower, price  \n\nThis heatmap has given us great insights into the data.  \nNow let us apply domain knowledge and ask the questions which will affect the price of the automobile."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7208e41e-b5e5-4aee-a76d-320f2c34c3fa"}}},{"cell_type":"markdown","source":["##### 4.2.1 - Checking some columns in more detail  \nWe can draw a vertical boxplot grouped by a categorical variable:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"41c3c5fc-a903-4eda-bb1b-f1e4e86515e5"}}},{"cell_type":"code","source":["fig, ax = plt.subplots(figsize=(16,8))\nsns.boxplot(x=\"fuel-type\", y=\"horsepower\", data=df, ax=ax)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"721c0795-e5f1-4086-a5de-39227ee1f9e0"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["And even add a third component:  \nhttps://seaborn.pydata.org/tutorial/categorical.html"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"21370d60-9213-4bb1-9db7-661b6718f0a3"}}},{"cell_type":"code","source":["#sns.catplot(x=\"fuel-type\", y=\"horsepower\", hue=\"num-of-doors\", kind=\"box\", data=df, height=8, aspect=2)\nsns.catplot(x=\"fuel-type\", y=\"horsepower\", hue=\"num-of-doors\", kind=\"violin\", inner=\"stick\", split=True, palette=\"pastel\", data=df, height=8, aspect=2)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cf069c12-0eef-418c-86f5-4ca6ddd7076b"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 5. Asking questions based on the analysis"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9f9bb85c-5cdd-4f09-b698-543e8c284ddc"}}},{"cell_type":"markdown","source":["Try to ask questions related to independent variables and the target variable.  \nExample questions related to this dataset could be:  \n\n+ How fuel_type will affect the price of the car?   \n+ How does the horsepower affect the price?  \n+ What is the relation between engine_size and price?  \n+ How does highway_mpg affects price?  \n+ What is the relation between no. of doors and price?"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3fc623bc-4ddf-4921-a103-acab47cff28f"}}},{"cell_type":"markdown","source":["#### 5.1 How fuel_type will affect the price?  \n\nLet's compare categorical data with numerical data. We are going to use a catplot from Seaborn, but there are other options for categorical variables:  \nhttps://seaborn.pydata.org/tutorial/categorical.html"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dca03423-c43b-4518-8eb2-d2eabe73e64e"}}},{"cell_type":"code","source":["plt.figure(figsize=(12,10))\n#https://seaborn.pydata.org/generated/seaborn.catplot.html#seaborn.catplot\nsns.catplot(x='fuel-type',y='price', data=df, height=8)\nplt.xlabel('Fuel Type')\nplt.ylabel('Price')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3268f742-b3f7-4395-9dd0-97cb0a5e876c"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### 5.2 How does the horsepower affect the price?  \n\nMatplotlib and Seaborn have very nice graphs to visualize numerical relationships:  \nhttps://seaborn.pydata.org/tutorial/relational.html  \nhttps://matplotlib.org/stable/gallery/index.html"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7f10b889-9d2c-4258-bd8a-9f25f15cdc51"}}},{"cell_type":"code","source":["plt.figure(figsize=(12,10))\n#https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html  \nplt.scatter(x='horsepower',y='price', data=df)\nplt.xlabel('Horsepower')\nplt.ylabel('Price')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b934c034-c536-4aee-9dab-b7468bb0291f"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#https://seaborn.pydata.org/generated/seaborn.jointplot.html\n\nsns.jointplot(x='horsepower',y='price', data=df)\nsns.jointplot(x='horsepower',y='price', data=df, kind='hex')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"922721ea-e9b3-4d02-b053-c468ea54aead"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["We can see that most of the horsepower value lies between 50-150 has price mostly between 5000-25000, there are outliers also(between 200-300).  \nLet’s see a count between 50-100 i.e univariate analysis of horsepower."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5ed7b896-4612-476b-bf6f-366bf8ffdbd0"}}},{"cell_type":"code","source":["plt.figure(figsize=(12,10))\n#https://seaborn.pydata.org/generated/seaborn.histplot.html\nsns.histplot(df.horsepower,bins=10)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b4c5aecc-c124-4c27-b29c-4c567b0572de"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["The average count between 50-100 is 50 and it is positively skewed."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9568b1e6-8c4e-4d55-9598-5605c7189717"}}},{"cell_type":"markdown","source":["#### 5.3 What is the relation between engine_size and price?"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"be0778bc-0b25-4365-9c93-ebd4b9e4c986"}}},{"cell_type":"code","source":["plt.figure(figsize=(12,10))\n#https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html  \nplt.scatter(x='engine-size',y='price',data=df)\nplt.xlabel('Engine size')\nplt.ylabel('Price')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ca48f2e3-e52f-4471-a05d-562741911b46"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["sns.jointplot(x='engine-size',y='price', data=df, kind='reg')\nsns.jointplot(x='engine-size',y='price', data=df, kind='kde')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eb6baf38-0588-4227-8f45-af7e8672b5fb"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["We can observe that the pattern is similar to horsepower vs price."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9d1423cd-3b67-4cf6-895a-115ed60adca2"}}},{"cell_type":"markdown","source":["#### 5.4 How does highway_mpg affects price?"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"50a11e24-e383-4de5-9819-428a60b9563a"}}},{"cell_type":"code","source":["plt.figure(figsize=(12,10))\n#https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html  \nplt.scatter(x='highway-mpg',y='price',data=df)\nplt.xlabel('Higway mpg')\nplt.ylabel('Price')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cddb9d80-f767-47ff-8022-5b1f2e20cd3d"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["We can see price decreases with an increase in higway_mpg."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5bda39cf-0eda-44e8-b5eb-212790a72a57"}}},{"cell_type":"markdown","source":["#### 5.5 What is the relation between no. of doors and price?  \n\nLet us first check the number of doors."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"16f00b65-bada-4423-bb28-c52d865cc4cb"}}},{"cell_type":"code","source":["#Unique values in num_of_doors\ndf[\"num-of-doors\"].value_counts().plot(kind=\"bar\", figsize=(10,6))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5dbcc2db-535d-4beb-8a72-85f54c706bde"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["plt.figure(figsize=(12,8))\n#https://seaborn.pydata.org/generated/seaborn.boxplot.html\nsns.boxplot(x='price', y='num-of-doors',data=df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"66c2eeb4-347b-45bb-8fd0-7bfd087cf324"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["With this boxplot, we can conclude that the average price of a vehicle with two doors is 10000,  and the average price of a vehicle with four doors is close to 12000.  \nWith this plot, we have gained enough insights from data and our data is ready to build a model."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"efe5aaf9-3a7f-476f-921e-f40bc2a25850"}}},{"cell_type":"markdown","source":["##### There are ways to explore relationships between more than two variables; although it can get a bit more complicated to interpret."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f62d0901-6246-4f24-b0a1-2ec3bc2845e8"}}},{"cell_type":"code","source":["#Create a pivot table for car manufactures and fuel with horsepower rate as values\ngrouped = pd.pivot_table(data=df,index='make',columns='fuel-type',values='horsepower',aggfunc='mean')\n\n#Create a heatmap to visualize manufactures, fuel type and horse power\nplt.figure(figsize=[12,10])\nsns.heatmap(grouped, annot=True, cmap='coolwarm', center=0.117)\n\nplt.title(\"Horse Power per Manufacturer\")\nplt.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b30d9c3a-8420-4bce-a03c-4d1cec5c4243"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"1_DS_workflow_EDA","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":4479417584936569}},"nbformat":4,"nbformat_minor":0}
